Из «Бета-Банка» ежемесячно стали уходить клиенты. Неббходимо было спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Исследователю были предоставлены исторические данные о поведении клиентов и расторжении договоров с банком.
Было необходимо построить модель с предельно большим значением F1-меры. Задачей также было довести метрику до 0.59 и проверить F1-меру на тестовой выборке самостоятельно.

В данном исследовании были использованы три модели, а именно, DecisionTreeClassifier (решющее дерево) RandomForestClassifier (случайный лес) LogisticRegression (логистическую регрессию)

Наилучшим результатом модели решающего дерева оказались F1 = 0,61 с глубиной 7. 
Лучшим результатом модели случайного леса оказались 97 деревьев со значением F1 = 0.5258.
Результаты логистической регресии оказались равны нулю из-за низкого precision и recall. 

Далее исследование был убран дисбаланс классов по условию задачи, чтобы посмотреть как поведут себя модели.

При сбалансированных классах модели показали следующие результаты:
DecisionTreeClassifier F1 = 0.5734
RandomForestClassifier F1 = 0.4459
LogisticRegression F1 = 0.5109 

При умньшении класса 0 модели показали следующие результаты:
DecisionTree F1 = 0.5698
RandomForest F1 = 0.5927
LogisticRegression F1 = 0.5074

При увеличении класса 1 модели показали следующие результаты:
DecisionTreeClassifier F1 = 0.5734
RandomForestClassifier F1 = 0.6013
LogisticRegression F1 = 0.5100

Был сделан вывод, что дисбаланс классов ухудшал работу моделей. 
Наилучшим способом решения данной проблемы стал увеличение класса 1 в тренировочной выборке.
Выравнивание классов привело к росту F1-меры, к росту гиперпараметров recall и падению гиперпараметра precision.
Выявили наилучшую модель, а именно RandomForrestClassifier.

Во время тестирования выборки модели показали следующие результаты:
Модель случайного леса - дисбаланс классов F1 = 0.4821
Модель случайного леса - взвешенные классы F1 = 0.5710
Случайный лес - уменьшенное количество классов 0 F1 = 0.5606
Модель случайного леса - увеличенное количество классов F1 = 0.5964

После тестрирования моделей, лучшей моделью была выбрана модель случайного леса (RandomForrest) со сбалансированными классами. 
Данная модель имеет достаточную адекватность, подтверждёнными данными ROC-AUC - 0.84. Точность попадания по классам довольно высокий = 0.841. Precision = 0.687, Recall = 0.456, Accuracy = 0.841, F1_score = 0.541